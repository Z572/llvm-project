; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV32I
; RUN: llc -mtriple=riscv64 -target-abi=ilp32 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64-ILP32

declare void @notdead(ptr)

; These tests must ensure the stack pointer is restored using the frame
; pointer

define void @simple_alloca(i32 %n) nounwind {
; RV32I-LABEL: simple_alloca:
; RV32I:       # %bb.0:
; RV32I-NEXT:    addi sp, sp, -16
; RV32I-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
; RV32I-NEXT:    addi s0, sp, 16
; RV32I-NEXT:    addi a0, a0, 15
; RV32I-NEXT:    andi a0, a0, -16
; RV32I-NEXT:    sub a0, sp, a0
; RV32I-NEXT:    mv sp, a0
; RV32I-NEXT:    call notdead@plt
; RV32I-NEXT:    addi sp, s0, -16
; RV32I-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s0, 8(sp) # 4-byte Folded Reload
; RV32I-NEXT:    addi sp, sp, 16
; RV32I-NEXT:    ret
;
; RV64-ILP32-LABEL: simple_alloca:
; RV64-ILP32:       # %bb.0:
; RV64-ILP32-NEXT:    addi sp, sp, -16
; RV64-ILP32-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    sd s0, 0(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    addi s0, sp, 16
; RV64-ILP32-NEXT:    slli a0, a0, 32
; RV64-ILP32-NEXT:    srli a0, a0, 32
; RV64-ILP32-NEXT:    addi a0, a0, 15
; RV64-ILP32-NEXT:    andi a0, a0, -16
; RV64-ILP32-NEXT:    sub a0, sp, a0
; RV64-ILP32-NEXT:    mv sp, a0
; RV64-ILP32-NEXT:    call notdead@plt
; RV64-ILP32-NEXT:    addi sp, s0, -16
; RV64-ILP32-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    ld s0, 0(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    addi sp, sp, 16
; RV64-ILP32-NEXT:    ret
  %1 = alloca i8, i32 %n
  call void @notdead(ptr %1)
  ret void
}

declare ptr @llvm.stacksave()
declare void @llvm.stackrestore(ptr)

define void @scoped_alloca(i32 %n) nounwind {
; RV32I-LABEL: scoped_alloca:
; RV32I:       # %bb.0:
; RV32I-NEXT:    addi sp, sp, -16
; RV32I-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s1, 4(sp) # 4-byte Folded Spill
; RV32I-NEXT:    addi s0, sp, 16
; RV32I-NEXT:    mv s1, sp
; RV32I-NEXT:    addi a0, a0, 15
; RV32I-NEXT:    andi a0, a0, -16
; RV32I-NEXT:    sub a0, sp, a0
; RV32I-NEXT:    mv sp, a0
; RV32I-NEXT:    call notdead@plt
; RV32I-NEXT:    mv sp, s1
; RV32I-NEXT:    addi sp, s0, -16
; RV32I-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s0, 8(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s1, 4(sp) # 4-byte Folded Reload
; RV32I-NEXT:    addi sp, sp, 16
; RV32I-NEXT:    ret
;
; RV64-ILP32-LABEL: scoped_alloca:
; RV64-ILP32:       # %bb.0:
; RV64-ILP32-NEXT:    addi sp, sp, -32
; RV64-ILP32-NEXT:    sd ra, 24(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    sd s0, 16(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    sd s1, 8(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    addi s0, sp, 32
; RV64-ILP32-NEXT:    mv s1, sp
; RV64-ILP32-NEXT:    slli a0, a0, 32
; RV64-ILP32-NEXT:    srli a0, a0, 32
; RV64-ILP32-NEXT:    addi a0, a0, 15
; RV64-ILP32-NEXT:    andi a0, a0, -16
; RV64-ILP32-NEXT:    sub a0, sp, a0
; RV64-ILP32-NEXT:    mv sp, a0
; RV64-ILP32-NEXT:    call notdead@plt
; RV64-ILP32-NEXT:    mv sp, s1
; RV64-ILP32-NEXT:    addi sp, s0, -32
; RV64-ILP32-NEXT:    ld ra, 24(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    ld s0, 16(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    ld s1, 8(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    addi sp, sp, 32
; RV64-ILP32-NEXT:    ret
  %sp = call ptr @llvm.stacksave()
  %addr = alloca i8, i32 %n
  call void @notdead(ptr %addr)
  call void @llvm.stackrestore(ptr %sp)
  ret void
}

declare void @func(ptr, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32)

; Check that outgoing arguments passed on the stack do not corrupt a
; variable-sized stack object.
define void @alloca_callframe(i32 %n) nounwind {
; RV32I-LABEL: alloca_callframe:
; RV32I:       # %bb.0:
; RV32I-NEXT:    addi sp, sp, -16
; RV32I-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
; RV32I-NEXT:    addi s0, sp, 16
; RV32I-NEXT:    addi a0, a0, 15
; RV32I-NEXT:    andi a0, a0, -16
; RV32I-NEXT:    sub a0, sp, a0
; RV32I-NEXT:    mv sp, a0
; RV32I-NEXT:    addi sp, sp, -16
; RV32I-NEXT:    li a1, 12
; RV32I-NEXT:    sw a1, 12(sp)
; RV32I-NEXT:    li a1, 11
; RV32I-NEXT:    sw a1, 8(sp)
; RV32I-NEXT:    li a1, 10
; RV32I-NEXT:    sw a1, 4(sp)
; RV32I-NEXT:    li t0, 9
; RV32I-NEXT:    li a1, 2
; RV32I-NEXT:    li a2, 3
; RV32I-NEXT:    li a3, 4
; RV32I-NEXT:    li a4, 5
; RV32I-NEXT:    li a5, 6
; RV32I-NEXT:    li a6, 7
; RV32I-NEXT:    li a7, 8
; RV32I-NEXT:    sw t0, 0(sp)
; RV32I-NEXT:    call func@plt
; RV32I-NEXT:    addi sp, sp, 16
; RV32I-NEXT:    addi sp, s0, -16
; RV32I-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s0, 8(sp) # 4-byte Folded Reload
; RV32I-NEXT:    addi sp, sp, 16
; RV32I-NEXT:    ret
;
; RV64-ILP32-LABEL: alloca_callframe:
; RV64-ILP32:       # %bb.0:
; RV64-ILP32-NEXT:    addi sp, sp, -16
; RV64-ILP32-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    sd s0, 0(sp) # 8-byte Folded Spill
; RV64-ILP32-NEXT:    addi s0, sp, 16
; RV64-ILP32-NEXT:    slli a0, a0, 32
; RV64-ILP32-NEXT:    srli a0, a0, 32
; RV64-ILP32-NEXT:    addi a0, a0, 15
; RV64-ILP32-NEXT:    andi a0, a0, -16
; RV64-ILP32-NEXT:    sub a0, sp, a0
; RV64-ILP32-NEXT:    mv sp, a0
; RV64-ILP32-NEXT:    addi sp, sp, -32
; RV64-ILP32-NEXT:    li a1, 12
; RV64-ILP32-NEXT:    sd a1, 24(sp)
; RV64-ILP32-NEXT:    li a1, 11
; RV64-ILP32-NEXT:    sd a1, 16(sp)
; RV64-ILP32-NEXT:    li a1, 10
; RV64-ILP32-NEXT:    sd a1, 8(sp)
; RV64-ILP32-NEXT:    li t0, 9
; RV64-ILP32-NEXT:    li a1, 2
; RV64-ILP32-NEXT:    li a2, 3
; RV64-ILP32-NEXT:    li a3, 4
; RV64-ILP32-NEXT:    li a4, 5
; RV64-ILP32-NEXT:    li a5, 6
; RV64-ILP32-NEXT:    li a6, 7
; RV64-ILP32-NEXT:    li a7, 8
; RV64-ILP32-NEXT:    sd t0, 0(sp)
; RV64-ILP32-NEXT:    call func@plt
; RV64-ILP32-NEXT:    addi sp, sp, 32
; RV64-ILP32-NEXT:    addi sp, s0, -16
; RV64-ILP32-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    ld s0, 0(sp) # 8-byte Folded Reload
; RV64-ILP32-NEXT:    addi sp, sp, 16
; RV64-ILP32-NEXT:    ret
  %1 = alloca i8, i32 %n
  call void @func(ptr %1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8,
                  i32 9, i32 10, i32 11, i32 12)
  ret void
}
